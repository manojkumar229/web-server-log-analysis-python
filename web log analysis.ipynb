{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98eb0efa",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This assessment involves analyzing the Calgary HTTP dataset, which contains approximately one year's worth of HTTP requests to the University of Calgary's Computer Science web server. You'll work with real-world web server log data to extract meaningful insights and demonstrate your Python data analysis skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81debeba",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c05313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  remotehost rfc931 authuser                       date    resource status  \\\n",
      "0      local      -        -  1994-10-24 13:41:41-06:00  index.html    200   \n",
      "1      local      -        -  1994-10-24 13:41:41-06:00       1.gif    200   \n",
      "2      local      -        -  1994-10-24 13:43:13-06:00  index.html    200   \n",
      "3      local      -        -  1994-10-24 13:43:14-06:00       2.gif    200   \n",
      "4      local      -        -  1994-10-24 13:43:15-06:00       3.gif    200   \n",
      "\n",
      "   bytes  \n",
      "0    150  \n",
      "1   1210  \n",
      "2   3185  \n",
      "3   2555  \n",
      "4  36403  \n",
      "\n",
      " 724910\n"
     ]
    }
   ],
   "source": [
    "# You can write your code here for data loading, cleaning, and exploration. Add cells as necessary.\n",
    "# importing all libraries\n",
    "import gzip\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter,defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# creating the empty list for appending the split data ( remotehost, rfc931, authuser, date, request, status, bytes)\n",
    "log = []\n",
    "\n",
    "# creating the required pattern using Regex\n",
    "pattern = r'(\\S+) (\\S+) (\\S+) \\[(.*?)\\] \"(.*?)\" (\\d{3}) (\\S+)'\n",
    "\n",
    "# reading the data from the zip file using gzip library\n",
    "with gzip.open(\"F:\\Data Analyst\\MapUp\\calgary_access_log.gz\",'rt',encoding='utf-8',errors='ignore') as document:\n",
    "    for l in document:\n",
    "        exact = re.match(pattern, l)\n",
    "        if exact:\n",
    "            # extraction starts using split\n",
    "            remotehost, rfc931, authuser, date, request, status, byte =exact.groups()\n",
    "            #print(request)\n",
    "            \n",
    "            # extracting file extention from file name\n",
    "            try:\n",
    "                method,resource,protocol = request.split()\n",
    "            except:\n",
    "                method,resource,protocol = None,None,None\n",
    "            #print(method,resource,protocol)\n",
    "            \n",
    "            # converting into datetime format using datetime library [24/Oct/1994:13:41:41 -0600]\n",
    "            try:\n",
    "                date_time = datetime.strptime(date,'%d/%b/%Y:%H:%M:%S %z')\n",
    "            except:\n",
    "                date_time=None\n",
    "            #print(date_time)\n",
    "            \n",
    "            # converting byte value into int.\n",
    "            byte_int = int(byte) if byte != '-' else 0\n",
    "            \n",
    "            #adding this modified data into the log list.\n",
    "            log.append(\n",
    "                {\n",
    "                    'remotehost' : remotehost,\n",
    "                    'rfc931' : rfc931,\n",
    "                    'authuser' : authuser,\n",
    "                    'date' : date_time,\n",
    "                    'resource' : resource,\n",
    "                    'status' : status,\n",
    "                    'bytes' : byte_int\n",
    "                }\n",
    "            )\n",
    "            \n",
    "# now creating the dataframe to perform cleaning and manipulating operations\n",
    "df = pd.DataFrame(log)\n",
    "print(df.head())\n",
    "\n",
    "print('\\n',df['remotehost'].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4918caa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remotehost                       object\n",
      "rfc931                           object\n",
      "authuser                         object\n",
      "date          datetime64[ns, UTC-06:00]\n",
      "resource                         object\n",
      "status                            int32\n",
      "bytes                             int64\n",
      "dtype: object \n",
      "\n",
      "  remotehost rfc931 authuser                      date    resource  status  \\\n",
      "0      local      -        - 1994-10-24 13:41:41-06:00  index.html     200   \n",
      "1      local      -        - 1994-10-24 13:41:41-06:00       1.gif     200   \n",
      "2      local      -        - 1994-10-24 13:43:13-06:00  index.html     200   \n",
      "3      local      -        - 1994-10-24 13:43:14-06:00       2.gif     200   \n",
      "4      local      -        - 1994-10-24 13:43:15-06:00       3.gif     200   \n",
      "\n",
      "   bytes     date_str  hour extension  \n",
      "0    150  24-Oct-1994    13      html  \n",
      "1   1210  24-Oct-1994    13       gif  \n",
      "2   3185  24-Oct-1994    13      html  \n",
      "3   2555  24-Oct-1994    13       gif  \n",
      "4  36403  24-Oct-1994    13       gif  \n",
      "\n",
      " count:  431879\n"
     ]
    }
   ],
   "source": [
    "#print(df.dtypes)\n",
    "# changing the datatype of date from objecct to date time\n",
    "df['date'] = pd.to_datetime(df['date'],format=\"%d/%b/%Y:%H:%M:%S %z\",errors='coerce')\n",
    "df['status'] = df['status'].astype(int)\n",
    "print(df.dtypes,'\\n')\n",
    "\n",
    "# cleaning the data where either of resource or date_time is null\n",
    "df.dropna(subset=['date','resource'],inplace = True)\n",
    "#print(df['date'].count())\n",
    "\n",
    "# adding extra column acc. to requirements like hour and extension of file\n",
    "df['date_str'] = df['date'].dt.strftime('%d-%b-%Y')\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['extension']=df['resource'].apply(lambda x:x.split('.')[-1])\n",
    "print(df.head())\n",
    "print('\\n','count: ',df['hour'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da5c6e",
   "metadata": {},
   "source": [
    "## Part 2: Analysis Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff13fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q1: Count of total log records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6264dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:\n",
      "431879\n"
     ]
    }
   ],
   "source": [
    "def total_log_records(dataframe) -> int:\n",
    "    \"\"\"\n",
    "    Q1: Count of total log records.\n",
    "\n",
    "    Objective:\n",
    "        Determine the total number of HTTP log entries in the dataset.\n",
    "        Each line in the log file represents one HTTP request.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of log entries.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count log records\n",
    "\n",
    "    return len(dataframe)  # Placeholder return\n",
    "\n",
    "\n",
    "answer1 = total_log_records(df)\n",
    "print(\"Answer 1:\")\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5141e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q2: Count of unique hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcbccae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def unique_host_count(dataframe) -> int:\n",
    "    \"\"\"\n",
    "    Q2: Count of unique hosts.\n",
    "\n",
    "    Objective:\n",
    "        Determine how many distinct hosts accessed the server.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of unique hosts.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count unique hosts\n",
    "    hosts = dataframe['remotehost'].unique()\n",
    "    #print(hosts)\n",
    "    uni_host = len(hosts)\n",
    "\n",
    "    return  uni_host # Placeholder return\n",
    "\n",
    "\n",
    "answer2 = unique_host_count(df)\n",
    "print(\"Answer 2:\")\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c224d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q3: Date-wise unique filename counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac11c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 3:\n",
      "{'01-Aug-1995': 669, '01-Jul-1995': 387, '01-Jun-1995': 590, '01-May-1995': 467, '01-Oct-1995': 552, '01-Sep-1995': 328, '02-Apr-1995': 438, '02-Aug-1995': 855, '02-Jul-1995': 397, '02-Jun-1995': 513, '02-May-1995': 701, '02-Oct-1995': 871, '02-Sep-1995': 349, '03-Apr-1995': 795, '03-Aug-1995': 582, '03-Jul-1995': 433, '03-Jun-1995': 398, '03-May-1995': 589, '03-Oct-1995': 846, '03-Sep-1995': 212, '04-Apr-1995': 821, '04-Aug-1995': 715, '04-Jul-1995': 610, '04-Jun-1995': 353, '04-May-1995': 684, '04-Oct-1995': 889, '04-Sep-1995': 340, '05-Apr-1995': 891, '05-Aug-1995': 507, '05-Jul-1995': 607, '05-Jun-1995': 494, '05-May-1995': 609, '05-Oct-1995': 846, '05-Sep-1995': 411, '06-Apr-1995': 678, '06-Aug-1995': 448, '06-Jul-1995': 522, '06-Jun-1995': 662, '06-May-1995': 517, '06-Oct-1995': 868, '06-Sep-1995': 549, '07-Apr-1995': 776, '07-Aug-1995': 608, '07-Jul-1995': 428, '07-Jun-1995': 486, '07-May-1995': 725, '07-Oct-1995': 468, '07-Sep-1995': 590, '08-Apr-1995': 542, '08-Aug-1995': 654, '08-Jul-1995': 277, '08-Jun-1995': 642, '08-May-1995': 656, '08-Oct-1995': 514, '08-Sep-1995': 754, '09-Apr-1995': 626, '09-Aug-1995': 698, '09-Jul-1995': 233, '09-Jun-1995': 468, '09-May-1995': 775, '09-Oct-1995': 742, '09-Sep-1995': 408, '10-Apr-1995': 751, '10-Aug-1995': 635, '10-Jul-1995': 502, '10-Jun-1995': 328, '10-May-1995': 794, '10-Oct-1995': 841, '10-Sep-1995': 455, '11-Apr-1995': 816, '11-Aug-1995': 451, '11-Jul-1995': 571, '11-Jun-1995': 297, '11-May-1995': 599, '11-Oct-1995': 717, '11-Sep-1995': 717, '12-Apr-1995': 887, '12-Aug-1995': 340, '12-Jul-1995': 467, '12-Jun-1995': 519, '12-May-1995': 469, '12-Sep-1995': 718, '13-Apr-1995': 613, '13-Aug-1995': 463, '13-Jul-1995': 499, '13-Jun-1995': 465, '13-May-1995': 289, '13-Sep-1995': 773, '14-Apr-1995': 353, '14-Aug-1995': 589, '14-Jul-1995': 551, '14-Jun-1995': 589, '14-May-1995': 326, '14-Sep-1995': 720, '15-Apr-1995': 418, '15-Aug-1995': 481, '15-Jul-1995': 384, '15-Jun-1995': 479, '15-May-1995': 584, '15-Sep-1995': 709, '16-Apr-1995': 434, '16-Aug-1995': 601, '16-Jul-1995': 299, '16-Jun-1995': 529, '16-May-1995': 432, '16-Sep-1995': 564, '17-Apr-1995': 446, '17-Aug-1995': 537, '17-Jul-1995': 568, '17-Jun-1995': 383, '17-May-1995': 508, '17-Sep-1995': 466, '18-Apr-1995': 452, '18-Aug-1995': 492, '18-Jul-1995': 557, '18-Jun-1995': 358, '18-May-1995': 528, '18-Sep-1995': 657, '19-Apr-1995': 704, '19-Aug-1995': 377, '19-Jul-1995': 471, '19-Jun-1995': 612, '19-May-1995': 499, '19-Sep-1995': 735, '20-Apr-1995': 587, '20-Aug-1995': 395, '20-Jul-1995': 569, '20-Jun-1995': 531, '20-May-1995': 254, '20-Sep-1995': 832, '21-Apr-1995': 713, '21-Aug-1995': 631, '21-Jul-1995': 649, '21-Jun-1995': 625, '21-May-1995': 288, '21-Sep-1995': 800, '22-Apr-1995': 435, '22-Aug-1995': 538, '22-Jul-1995': 444, '22-Jun-1995': 630, '22-May-1995': 477, '22-Sep-1995': 615, '23-Apr-1995': 332, '23-Aug-1995': 660, '23-Jul-1995': 498, '23-Jun-1995': 561, '23-May-1995': 565, '23-Sep-1995': 502, '24-Apr-1995': 529, '24-Aug-1995': 578, '24-Jul-1995': 565, '24-Jun-1995': 396, '24-May-1995': 490, '24-Oct-1994': 228, '24-Sep-1995': 593, '25-Apr-1995': 557, '25-Aug-1995': 595, '25-Jul-1995': 588, '25-Jun-1995': 569, '25-May-1995': 487, '25-Oct-1994': 319, '25-Sep-1995': 723, '26-Apr-1995': 647, '26-Aug-1995': 394, '26-Jul-1995': 598, '26-Jun-1995': 638, '26-May-1995': 424, '26-Oct-1994': 377, '26-Sep-1995': 871, '27-Apr-1995': 616, '27-Aug-1995': 436, '27-Jul-1995': 614, '27-Jun-1995': 518, '27-May-1995': 244, '27-Oct-1994': 384, '27-Sep-1995': 826, '28-Apr-1995': 637, '28-Aug-1995': 548, '28-Jul-1995': 564, '28-Jun-1995': 583, '28-May-1995': 205, '28-Oct-1994': 399, '28-Sep-1995': 867, '29-Apr-1995': 449, '29-Aug-1995': 511, '29-Jul-1995': 320, '29-Jun-1995': 469, '29-May-1995': 464, '29-Oct-1994': 254, '29-Sep-1995': 838, '30-Apr-1995': 277, '30-Aug-1995': 593, '30-Jul-1995': 481, '30-Jun-1995': 461, '30-May-1995': 553, '30-Oct-1994': 20, '30-Sep-1995': 650, '31-Aug-1995': 509, '31-Jul-1995': 622, '31-May-1995': 571}\n"
     ]
    }
   ],
   "source": [
    "def datewise_unique_filename_counts(dataframe) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Q3: Date-wise unique filename counts.\n",
    "\n",
    "    Objective:\n",
    "        For each date, count the number of unique filenames that accessed the server.\n",
    "        The date should be in 'dd-MMM-yyyy' format (e.g., '01-Jul-1995').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each date to its count of unique filenames.\n",
    "              Example: {'01-Jul-1995': 123, '02-Jul-1995': 150}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for date-wise unique filename counts\n",
    "    dict_uni_filenames = d = dataframe.groupby(['date_str'])['resource'].nunique().to_dict()\n",
    "\n",
    "    return d  # Placeholder return\n",
    "\n",
    "\n",
    "answer3 = datewise_unique_filename_counts(df)\n",
    "print(\"Answer 3:\")\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2da36a",
   "metadata": {},
   "source": [
    "### Q4: Number of 404 response codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0671865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 4:\n",
      "14586\n"
     ]
    }
   ],
   "source": [
    "def count_404_errors(dataframe) -> int:\n",
    "    \"\"\"\n",
    "    Q4: Number of 404 response codes.\n",
    "\n",
    "    Objective:\n",
    "        Count how many times the HTTP 404 Not Found status appears in the logs.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of 404 errors.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count 404 errors\n",
    "    error404 = len(dataframe[dataframe['status']==404])\n",
    "\n",
    "    return error404  # Placeholder return\n",
    "\n",
    "\n",
    "answer4 = count_404_errors(df)\n",
    "print(\"Answer 4:\")\n",
    "print(answer4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73928d2",
   "metadata": {},
   "source": [
    "### Q5: Top 15 filenames with 404 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358f0523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 5:\n",
      "[('index.html', 3119), ('4115.html', 901), ('1611.html', 647), ('5698.xbm', 500), ('710.txt', 254), ('10695.ps', 161), ('6555.html', 153), ('9678.gif', 142), ('3268.gif', 138), ('9814.gif', 134), ('11059.gif', 129), ('11060.gif', 129), ('9388.xbm', 120), ('151.html', 119), ('1685.html', 113)]\n"
     ]
    }
   ],
   "source": [
    "def top_15_filenames_with_404(dataframe) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q5: Top 15 filenames with 404 responses.\n",
    "\n",
    "    Objective:\n",
    "        Identify which requested URLs most frequently resulted in a 404 error.\n",
    "        Return the top 15 filenames sorted by frequency.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (filename, count), sorted by count in descending order.\n",
    "              Example: [('index.html', 200), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 15 filenames with 404\n",
    "    top_15 = dataframe[dataframe['status']==404]['resource'].value_counts().head(15)\n",
    "    list_top_15 = list(top_15.items())\n",
    "\n",
    "    return list_top_15  # Placeholder return\n",
    "\n",
    "\n",
    "answer5 = top_15_filenames_with_404(df)\n",
    "print(\"Answer 5:\")\n",
    "print(answer5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328c88a",
   "metadata": {},
   "source": [
    "### Q6: Top 15 file extension with 404 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0aca8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 6:\n",
      "[('html', 8051), ('gif', 4013), ('xbm', 665), ('ps', 562), ('txt', 265), ('jpg', 200), ('cgi', 76), ('GIF', 42), ('htm', 40), ('gif\"', 34), ('com', 29), ('com/', 24), ('dvi', 23), ('rgb', 21), ('html/', 21)]\n"
     ]
    }
   ],
   "source": [
    "def top_15_ext_with_404(dataframe) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q6: Top 15 file extensions with 404 responses.\n",
    "\n",
    "    Objective:\n",
    "        Find which file extensions generated the most 404 errors.\n",
    "        Return the top 15 sorted by number of 404s.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (extension, count), sorted by count in descending order.\n",
    "              Example: [('html', 45), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 15 extensions with 404\n",
    "    top_15 = dataframe[dataframe['status']==404]['extension'].value_counts().head(15)\n",
    "    list_top_15_ext = list(top_15.items())\n",
    "    return list_top_15_ext  # Placeholder return\n",
    "\n",
    "\n",
    "answer6 = top_15_ext_with_404(df)\n",
    "print(\"Answer 6:\")\n",
    "print(answer6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52c8ba",
   "metadata": {},
   "source": [
    "### Q7: Total bandwidth transferred per day for the month of July 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f52d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 7:\n",
      "{'01-Jul-1995': 11333976, '02-Jul-1995': 8653986, '03-Jul-1995': 13508529, '04-Jul-1995': 26565884, '05-Jul-1995': 19541225, '06-Jul-1995': 19752989, '07-Jul-1995': 9427822, '08-Jul-1995': 5403491, '09-Jul-1995': 4660556, '10-Jul-1995': 14912796, '11-Jul-1995': 22503471, '12-Jul-1995': 17365039, '13-Jul-1995': 15986302, '14-Jul-1995': 19184404, '15-Jul-1995': 15769181, '16-Jul-1995': 9005564, '17-Jul-1995': 19596435, '18-Jul-1995': 17096829, '19-Jul-1995': 17847673, '20-Jul-1995': 20751717, '21-Jul-1995': 25455607, '22-Jul-1995': 8059932, '23-Jul-1995': 9577795, '24-Jul-1995': 22298075, '25-Jul-1995': 24472760, '26-Jul-1995': 24564950, '27-Jul-1995': 25967969, '28-Jul-1995': 36456855, '29-Jul-1995': 11684209, '30-Jul-1995': 23158170, '31-Jul-1995': 30715614}\n"
     ]
    }
   ],
   "source": [
    "def total_bandwidth_per_day(dataframe) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Q7: Total bandwidth transferred per day for the month of July 1995.\n",
    "\n",
    "    Objective:\n",
    "        Sum the number of bytes transferred per day.\n",
    "        Skip entries where the byte field is missing or '-'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each date to total bytes transferred.\n",
    "              Example: {'01-Jul-1995': 123456789, ...}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to compute total bandwidth per day\n",
    "    july_1995 = dataframe[dataframe['date'].dt.strftime('%b-%Y')=='Jul-1995'] \n",
    "    july_1995_byte = july_1995.groupby(['date_str'])['bytes'].sum().to_dict()\n",
    "    return july_1995_byte  # Placeholder return\n",
    "\n",
    "\n",
    "answer7 = total_bandwidth_per_day(df)\n",
    "print(\"Answer 7:\")\n",
    "print(answer7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc00908",
   "metadata": {},
   "source": [
    "### Q8: Hourly request distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77f3e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 8:\n",
      "{0: 11510, 1: 9832, 2: 9346, 3: 8101, 4: 7789, 5: 8234, 6: 9750, 7: 11896, 8: 17302, 9: 21637, 10: 25627, 11: 28584, 12: 26749, 13: 29997, 14: 29636, 15: 28041, 16: 28202, 17: 23229, 18: 17778, 19: 17253, 20: 17437, 21: 15915, 22: 14500, 23: 13534}\n"
     ]
    }
   ],
   "source": [
    "def hourly_request_distribution(dataframe) -> dict[int, int]:\n",
    "    \"\"\"\n",
    "    Q8: Hourly request distribution.\n",
    "\n",
    "    Objective:\n",
    "        Count the number of requests made during each hour (00 to 23).\n",
    "        Useful for understanding traffic peaks.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping hour (int) to request count.\n",
    "              Example: {0: 120, 1: 90, ..., 23: 80}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for hourly distribution\n",
    "    hour_count = dataframe['hour'].value_counts().sort_index().to_dict()\n",
    "\n",
    "    return hour_count  # Placeholder return\n",
    "\n",
    "\n",
    "answer8 = hourly_request_distribution(df)\n",
    "print(\"Answer 8:\")\n",
    "print(answer8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b7083",
   "metadata": {},
   "source": [
    "### Q9: Top 10 most requested filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91168ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 9:\n",
      "[('index.html', 75299), ('3.gif', 11949), ('2.gif', 11559), ('4097.gif', 4733), ('8870.jpg', 4492), ('244.gif', 4339), ('6733.gif', 4278), ('8472.gif', 3843), ('8308.gif', 3478), ('4.gif', 3357)]\n"
     ]
    }
   ],
   "source": [
    "def top_10_most_requested_filenames(dataframe) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q9: Top 10 most requested filenames.\n",
    "\n",
    "    Objective:\n",
    "        Identify the most commonly requested URLs (irrespective of status code).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (filename, count), sorted by count in descending order.\n",
    "                Example: [('index.html', 500), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 10 most requested filenames\n",
    "    filenames = dataframe['resource'].value_counts().head(10)\n",
    "    top_10 = list(filenames.items())\n",
    "\n",
    "    return top_10  # Placeholder return\n",
    "\n",
    "\n",
    "answer9 = top_10_most_requested_filenames(df)\n",
    "print(\"Answer 9:\")\n",
    "print(answer9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb4778",
   "metadata": {},
   "source": [
    "### Q10: HTTP response code distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4453ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 10:\n",
      "{200: 328438, 304: 70131, 302: 16595, 404: 14586, 403: 2022, 401: 46, 500: 28, 501: 26, 400: 7}\n"
     ]
    }
   ],
   "source": [
    "def response_code_distribution(dataframe) -> dict[int, int]:\n",
    "    \"\"\"\n",
    "    Q10: HTTP response code distribution.\n",
    "\n",
    "    Objective:\n",
    "        Count how often each HTTP status code appears in the logs.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping HTTP status codes (as int) to their frequency.\n",
    "              Example: {200: 150000, 404: 3000}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for response code counts\n",
    "    code_response = dataframe['status'].value_counts().to_dict()\n",
    "\n",
    "    return code_response  # Placeholder return\n",
    "\n",
    "\n",
    "answer10 = response_code_distribution(df)\n",
    "print(\"Answer 10:\")\n",
    "print(answer10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
